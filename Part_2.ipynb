{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Will cover follwoing topics\n",
    "- Dataframe\n",
    "- Reading Dataset\n",
    "- Schema \n",
    "- Description \n",
    "- Adding columns\n",
    "- Dropping columns \n",
    "- Rename columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Dataframe\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.52:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x15ad7da10>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark # Here you can see my old sparksession, because I have not stopped it. In order to start new session you have to kill first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop() # Stop the session and create new one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Dataframe\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.52:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Dataframe</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x15ad5a250>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to read a dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets read the dataset \n",
    "df_pyspark = spark.read.option(\"header\", \"true\").csv(\"/Volumes/Jagannath/Fall 2024/Cloud Computing/PySpark/gene_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+----------------+------------------+--------------------+\n",
      "|Gene Name|Gene Count|Gene Length (kb)|Associated Studies| Functional Category|\n",
      "+---------+----------+----------------+------------------+--------------------+\n",
      "|    BRCA1|       120|            81.2|                35|          DNA Repair|\n",
      "|     TP53|        95|            20.1|                40|   Tumor Suppression|\n",
      "|     APOE|        80|             3.7|                25|    Lipid Metabolism|\n",
      "|     CFTR|        65|           189.9|                20|       Ion Transport|\n",
      "|     KRAS|        45|              42|                18| Signal Transduction|\n",
      "|     EGFR|        60|           189.5|                30|Cell Growth and P...|\n",
      "+---------+----------+----------------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Gene Name: string (nullable = true)\n",
      " |-- Gene Count: string (nullable = true)\n",
      " |-- Gene Length (kb): string (nullable = true)\n",
      " |-- Associated Studies: string (nullable = true)\n",
      " |-- Functional Category: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema() \n",
    "# One thing to observe is you can see Name, count, gene length all are as String. However count and length contains number, but still its showing as string. Why? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is one more function called inferSchema, it should be true to see values as integers \n",
    "df_pyspark = spark.read.option(\"header\", \"true\").csv(\"/Volumes/Jagannath/Fall 2024/Cloud Computing/PySpark/gene_data.csv\", inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+----------------+------------------+--------------------+\n",
      "|Gene Name|Gene Count|Gene Length (kb)|Associated Studies| Functional Category|\n",
      "+---------+----------+----------------+------------------+--------------------+\n",
      "|    BRCA1|       120|            81.2|                35|          DNA Repair|\n",
      "|     TP53|        95|            20.1|                40|   Tumor Suppression|\n",
      "|     APOE|        80|             3.7|                25|    Lipid Metabolism|\n",
      "|     CFTR|        65|           189.9|                20|       Ion Transport|\n",
      "|     KRAS|        45|            42.0|                18| Signal Transduction|\n",
      "|     EGFR|        60|           189.5|                30|Cell Growth and P...|\n",
      "+---------+----------+----------------+------------------+--------------------+\n",
      "\n",
      "root\n",
      " |-- Gene Name: string (nullable = true)\n",
      " |-- Gene Count: integer (nullable = true)\n",
      " |-- Gene Length (kb): double (nullable = true)\n",
      " |-- Associated Studies: integer (nullable = true)\n",
      " |-- Functional Category: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check Schema\n",
    "\n",
    "df_pyspark.show()\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Gene Name='BRCA1', Gene Count=120, Gene Length (kb)=81.2, Associated Studies=35, Functional Category='DNA Repair'),\n",
       " Row(Gene Name='TP53', Gene Count=95, Gene Length (kb)=20.1, Associated Studies=40, Functional Category='Tumor Suppression'),\n",
       " Row(Gene Name='APOE', Gene Count=80, Gene Length (kb)=3.7, Associated Studies=25, Functional Category='Lipid Metabolism'),\n",
       " Row(Gene Name='CFTR', Gene Count=65, Gene Length (kb)=189.9, Associated Studies=20, Functional Category='Ion Transport'),\n",
       " Row(Gene Name='KRAS', Gene Count=45, Gene Length (kb)=42.0, Associated Studies=18, Functional Category='Signal Transduction')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head(5) # In pandas we get head in dataframe format but in spark we get in list format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Gene Name: string]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.select(\"Gene Name\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|Gene Name|\n",
      "+---------+\n",
      "|    BRCA1|\n",
      "|     TP53|\n",
      "|     APOE|\n",
      "|     CFTR|\n",
      "|     KRAS|\n",
      "|     EGFR|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select(\"Gene Name\").show() # This will give you entire Name column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|Gene Name|Gene Count|\n",
      "+---------+----------+\n",
      "|    BRCA1|       120|\n",
      "|     TP53|        95|\n",
      "|     APOE|        80|\n",
      "|     CFTR|        65|\n",
      "|     KRAS|        45|\n",
      "|     EGFR|        60|\n",
      "+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pick multiple columns \n",
    "df_pyspark.select(['Gene Name', 'Gene Count']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Gene Name', 'string'),\n",
       " ('Gene Count', 'int'),\n",
       " ('Gene Length (kb)', 'double'),\n",
       " ('Associated Studies', 'int'),\n",
       " ('Functional Category', 'string')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Datatype\n",
    "df_pyspark.dtypes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/30 12:45:58 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------------------+-----------------+------------------+--------------------+\n",
      "|summary|Gene Name|        Gene Count| Gene Length (kb)|Associated Studies| Functional Category|\n",
      "+-------+---------+------------------+-----------------+------------------+--------------------+\n",
      "|  count|        6|                 6|                6|                 6|                   6|\n",
      "|   mean|     NULL|              77.5|87.73333333333335|              28.0|                NULL|\n",
      "| stddev|     NULL|26.972207918522354|83.14393944640022| 8.602325267042628|                NULL|\n",
      "|    min|     APOE|                45|              3.7|                18|Cell Growth and P...|\n",
      "|    max|     TP53|               120|            189.9|                40|   Tumor Suppression|\n",
      "+-------+---------+------------------+-----------------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show()\n",
    "# The .describe() function in PySpark is designed to summarize numeric columns by default. It calculates statistics like mean, stddev, min, and max that are only applicable to numeric data types.\n",
    "# In our dataset, the columns “Gene Name” and “Functional Category” are non-numeric (likely string data types), so .describe() does not calculate meaningful statistics for these fields, leading to the NULL values we see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Gene Name: string, Gene Count: int, Gene Length (kb): double, Associated Studies: int, Functional Category: string, Gene Count multiply by 2: int]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the columns\n",
    "\n",
    "df_pyspark.withColumn(\"Gene Count multiply by 2\", df_pyspark['Gene Count']*2) # You can see new column has been added. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+----------------+------------------+--------------------+------------------------+\n",
      "|Gene Name|Gene Count|Gene Length (kb)|Associated Studies| Functional Category|Gene Count multiply by 2|\n",
      "+---------+----------+----------------+------------------+--------------------+------------------------+\n",
      "|    BRCA1|       120|            81.2|                35|          DNA Repair|                     240|\n",
      "|     TP53|        95|            20.1|                40|   Tumor Suppression|                     190|\n",
      "|     APOE|        80|             3.7|                25|    Lipid Metabolism|                     160|\n",
      "|     CFTR|        65|           189.9|                20|       Ion Transport|                     130|\n",
      "|     KRAS|        45|            42.0|                18| Signal Transduction|                      90|\n",
      "|     EGFR|        60|           189.5|                30|Cell Growth and P...|                     120|\n",
      "+---------+----------+----------------+------------------+--------------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.withColumn(\"Gene Count multiply by 2\", df_pyspark['Gene Count']*2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns \n",
    "\n",
    "df_pyspark = df_pyspark.drop(\"Gene Count multiply by 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+----------------+------------------+--------------------+\n",
      "|Gene Name|Gene Count|Gene Length (kb)|Associated Studies| Functional Category|\n",
      "+---------+----------+----------------+------------------+--------------------+\n",
      "|    BRCA1|       120|            81.2|                35|          DNA Repair|\n",
      "|     TP53|        95|            20.1|                40|   Tumor Suppression|\n",
      "|     APOE|        80|             3.7|                25|    Lipid Metabolism|\n",
      "|     CFTR|        65|           189.9|                20|       Ion Transport|\n",
      "|     KRAS|        45|            42.0|                18| Signal Transduction|\n",
      "|     EGFR|        60|           189.5|                30|Cell Growth and P...|\n",
      "+---------+----------+----------------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+----------------+------------------+--------------------+\n",
      "|New Gene Name|Gene Count|Gene Length (kb)|Associated Studies| Functional Category|\n",
      "+-------------+----------+----------------+------------------+--------------------+\n",
      "|        BRCA1|       120|            81.2|                35|          DNA Repair|\n",
      "|         TP53|        95|            20.1|                40|   Tumor Suppression|\n",
      "|         APOE|        80|             3.7|                25|    Lipid Metabolism|\n",
      "|         CFTR|        65|           189.9|                20|       Ion Transport|\n",
      "|         KRAS|        45|            42.0|                18| Signal Transduction|\n",
      "|         EGFR|        60|           189.5|                30|Cell Growth and P...|\n",
      "+-------------+----------+----------------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rename the columns \n",
    "\n",
    "df_pyspark.withColumnRenamed(\"Gene Name\", \"New Gene Name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+----------------+------------------+--------------------+\n",
      "|Gene Name|Gene Count|Gene Length (kb)|Associated Studies| Functional Category|\n",
      "+---------+----------+----------------+------------------+--------------------+\n",
      "|    BRCA1|       120|            81.2|                35|          DNA Repair|\n",
      "|     TP53|        95|            20.1|                40|   Tumor Suppression|\n",
      "|     APOE|        80|             3.7|                25|    Lipid Metabolism|\n",
      "|     CFTR|        65|           189.9|                20|       Ion Transport|\n",
      "|     KRAS|        45|            42.0|                18| Signal Transduction|\n",
      "|     EGFR|        60|           189.5|                30|Cell Growth and P...|\n",
      "+---------+----------+----------------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show() # New name has not changed in df, because we have not assigned the df above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = df_pyspark.withColumnRenamed(\"Gene Name\", \"New Gene Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+----------------+------------------+--------------------+\n",
      "|New Gene Name|Gene Count|Gene Length (kb)|Associated Studies| Functional Category|\n",
      "+-------------+----------+----------------+------------------+--------------------+\n",
      "|        BRCA1|       120|            81.2|                35|          DNA Repair|\n",
      "|         TP53|        95|            20.1|                40|   Tumor Suppression|\n",
      "|         APOE|        80|             3.7|                25|    Lipid Metabolism|\n",
      "|         CFTR|        65|           189.9|                20|       Ion Transport|\n",
      "|         KRAS|        45|            42.0|                18| Signal Transduction|\n",
      "|         EGFR|        60|           189.5|                30|Cell Growth and P...|\n",
      "+-------------+----------+----------------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show() # Now you can see the updated df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
